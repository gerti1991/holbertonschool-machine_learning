{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a3e323",
   "metadata": {},
   "source": [
    "# Wisconsin Breast Cancer Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook focuses on classifying breast cancer tumors as malignant or benign based on features like tumor size, texture, and shape. This is a binary classification problem where:\n",
    "\n",
    "- Malignant: Cancerous tumor\n",
    "- Benign: Non-cancerous tumor\n",
    "\n",
    "We'll explore the dataset, preprocess the data, and implement multiple machine learning models to solve this classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ec95a",
   "metadata": {},
   "source": [
    "## Data Loading and Understanding\n",
    "\n",
    "First, we'll import the necessary libraries and load the Wisconsin Breast Cancer dataset which is available in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56238d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Load the Wisconsin Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "\n",
    "# Check the shape of the data\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {X.shape[0]}\")\n",
    "\n",
    "# Display target distribution\n",
    "target_counts = pd.Series(data.target).value_counts()\n",
    "print(f\"\\nTarget distribution:\\n{target_counts}\")\n",
    "print(f\"Target names: {data.target_names}\")\n",
    "\n",
    "# Preview the first few rows of the dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048bcd6",
   "metadata": {},
   "source": [
    "### Understanding the Features\n",
    "\n",
    "Let's explore the dataset's features and see how they relate to the target variable. We'll first look at basic statistical information and then visualize feature distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of the features\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6eef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame combining features and target for analysis\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in dataset:\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations between features\n",
    "plt.figure(figsize=(16, 14))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98fd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation with target\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Sort correlations with target\n",
    "target_corr = correlation_matrix['target'].sort_values(ascending=False)\n",
    "# Exclude target self-correlation\n",
    "target_corr = target_corr[target_corr.index != 'target']\n",
    "# Plot top correlations\n",
    "sns.barplot(x=target_corr.values, y=target_corr.index)\n",
    "plt.title('Feature Correlations with Target')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cdbaae",
   "metadata": {},
   "source": [
    "### Feature Distribution by Target Class\n",
    "\n",
    "Let's visualize how the distributions of key features differ between malignant and benign tumors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef505586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few important features based on correlation\n",
    "top_features = target_corr.index[:5]\n",
    "\n",
    "# Create pair plots to visualize relationships\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(top_features):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.histplot(data=df, x=feature, hue='target', kde=True, bins=30)\n",
    "    plt.title(f\"{feature} Distribution by Class\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bfc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot for the top correlated features\n",
    "subset_df = df[list(top_features) + ['target']]\n",
    "sns.pairplot(subset_df, hue='target', diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Top Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17dea87",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Now that we understand our data, let's prepare it for modeling. We need to:\n",
    "1. Split the data into training and testing sets\n",
    "2. Scale the features to standardize their ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53effced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Check the shapes of our splits\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the mean and standard deviation of the scaled data\n",
    "print(\"Training data mean after scaling:\", X_train_scaled.mean(axis=0)[:5], \"...\")\n",
    "print(\"Training data std after scaling:\", X_train_scaled.std(axis=0)[:5], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6b898",
   "metadata": {},
   "source": [
    "## Model Development: Neural Network\n",
    "\n",
    "Now we'll build a feedforward neural network using TensorFlow and Keras to classify the tumors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b607077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow and Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Build a neural network model\n",
    "def build_nn_model():\n",
    "    model = Sequential([\n",
    "        # Input layer (30 features)\n",
    "        Dense(64, activation='relu', input_shape=(30,)),\n",
    "        Dropout(0.2),  # Regularization to prevent overfitting\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        # Output layer - binary classification\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "nn_model = build_nn_model()\n",
    "\n",
    "# Display the model summary\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ecded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Record start time for model training\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "nn_training_time = time.time() - start_time\n",
    "print(f\"Neural Network training time: {nn_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbc62e",
   "metadata": {},
   "source": [
    "### Visualize Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a662d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa52d2a8",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Now we'll evaluate our neural network's performance on the test set. We'll look at various metrics including accuracy, precision, recall, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions with the neural network\n",
    "y_pred_nn_prob = nn_model.predict(X_test_scaled)\n",
    "y_pred_nn = (y_pred_nn_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "nn_precision = precision_score(y_test, y_pred_nn)\n",
    "nn_recall = recall_score(y_test, y_pred_nn)\n",
    "nn_f1 = f1_score(y_test, y_pred_nn)\n",
    "\n",
    "# Print results\n",
    "print(\"Neural Network Performance:\")\n",
    "print(f\"Accuracy: {nn_accuracy:.4f}\")\n",
    "print(f\"Precision: {nn_precision:.4f}\")\n",
    "print(f\"Recall: {nn_recall:.4f}\")\n",
    "print(f\"F1 Score: {nn_f1:.4f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn, target_names=['Malignant', 'Benign']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a89bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and visualize confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_nn)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Malignant', 'Benign'],\n",
    "            yticklabels=['Malignant', 'Benign'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - Neural Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3751ae",
   "metadata": {},
   "source": [
    "### Understanding Evaluation Metrics\n",
    "\n",
    "- **Accuracy**: The proportion of correct predictions among the total number of cases examined.\n",
    "  - Formula: (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "- **Precision**: The proportion of positive identifications that were actually correct.\n",
    "  - Formula: TP / (TP + FP)\n",
    "  - In our context: \"When the model predicts a tumor is benign, how often is it correct?\"\n",
    "\n",
    "- **Recall (Sensitivity)**: The proportion of actual positives that were identified correctly.\n",
    "  - Formula: TP / (TP + FN)\n",
    "  - In our context: \"Of all the actual benign tumors, how many did the model identify correctly?\"\n",
    "\n",
    "- **F1 Score**: The harmonic mean of precision and recall, providing a balance between them.\n",
    "  - Formula: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "In a medical context like cancer detection, recall is particularly important as we want to minimize false negatives (missing actual cancer cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bbde6",
   "metadata": {},
   "source": [
    "## Comparison with Simpler Models\n",
    "\n",
    "Now we'll compare our neural network with simpler models: Decision Tree and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize models\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Dictionary to store results\n",
    "model_results = {}\n",
    "\n",
    "# Train and evaluate decision tree\n",
    "start_time = time.time()\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "dt_training_time = time.time() - start_time\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Store decision tree results\n",
    "model_results['Decision Tree'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_dt),\n",
    "    'precision': precision_score(y_test, y_pred_dt),\n",
    "    'recall': recall_score(y_test, y_pred_dt),\n",
    "    'f1': f1_score(y_test, y_pred_dt),\n",
    "    'time': dt_training_time\n",
    "}\n",
    "\n",
    "# Train and evaluate logistic regression\n",
    "start_time = time.time()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_training_time = time.time() - start_time\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Store logistic regression results\n",
    "model_results['Logistic Regression'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'precision': precision_score(y_test, y_pred_lr),\n",
    "    'recall': recall_score(y_test, y_pred_lr),\n",
    "    'f1': f1_score(y_test, y_pred_lr),\n",
    "    'time': lr_training_time\n",
    "}\n",
    "\n",
    "# Add neural network results to dictionary\n",
    "model_results['Neural Network'] = {\n",
    "    'accuracy': nn_accuracy,\n",
    "    'precision': nn_precision,\n",
    "    'recall': nn_recall,\n",
    "    'f1': nn_f1,\n",
    "    'time': nn_training_time\n",
    "}\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in model_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"Training Time: {metrics['time']:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "model_names = list(model_results.keys())\n",
    "comparison_data = []\n",
    "\n",
    "for metric in metrics:\n",
    "    for model in model_names:\n",
    "        comparison_data.append({\n",
    "            'Model': model,\n",
    "            'Metric': metric.capitalize(),\n",
    "            'Value': model_results[model][metric]\n",
    "        })\n",
    "        \n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Performance metrics comparison\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(x='Metric', y='Value', hue='Model', data=comparison_df)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylim(0.9, 1.0)  # Adjust as needed based on actual results\n",
    "plt.legend(title='Model')\n",
    "\n",
    "# Training time comparison\n",
    "plt.subplot(2, 1, 2)\n",
    "training_times = [model_results[model]['time'] for model in model_names]\n",
    "plt.bar(model_names, training_times)\n",
    "plt.title('Model Training Time Comparison')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xlabel('Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a182e88",
   "metadata": {},
   "source": [
    "## Analysis and Conclusion\n",
    "\n",
    "### Neural Network Effectiveness\n",
    "\n",
    "The neural network's effectiveness for this problem can be evaluated from several perspectives:\n",
    "\n",
    "**Strengths of Neural Networks for this problem:**\n",
    "1. **Complex Pattern Recognition**: Neural networks excel at capturing complex, non-linear relationships between features, which may be present in medical data.\n",
    "2. **Feature Learning**: The hidden layers can automatically learn useful intermediate representations of the data.\n",
    "3. **Robustness**: With regularization techniques like dropout, neural networks can be robust against overfitting, especially important in medical contexts.\n",
    "\n",
    "**Limitations:**\n",
    "1. **Computation Cost**: As we've seen in the training time comparison, neural networks typically take longer to train compared to simpler models.\n",
    "2. **Interpretability**: Neural networks are often considered \"black boxes\" - it's difficult to explain precisely why they make specific predictions, which can be problematic in medical applications.\n",
    "3. **Data Requirements**: They typically perform best with large amounts of data, which may not always be available in medical contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa38173",
   "metadata": {},
   "source": [
    "## Analysis and Reflection\n",
    "\n",
    "### Model Effectiveness Comparison\n",
    "\n",
    "In this analysis, we've compared three different models for breast cancer classification:\n",
    "\n",
    "1. **Neural Network**: A multi-layer feedforward model with dropout for regularization\n",
    "2. **Logistic Regression**: A linear model that's often effective for binary classification\n",
    "3. **Decision Tree**: A non-linear model that creates decision boundaries based on feature thresholds\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- **Performance Metrics**: All three models achieved high accuracy, precision, and recall on the test set, suggesting that the breast cancer classification task is well-suited for machine learning approaches.\n",
    "\n",
    "- **Complexity vs. Performance**: The neural network, despite being more complex, didn't necessarily outperform the simpler models by a significant margin. This is an important observation as it demonstrates that simpler models can sometimes be equally effective for certain problems.\n",
    "\n",
    "- **ROC Curves**: The ROC curves and AUC scores show that all models are good at distinguishing between the two classes, with possibly slight advantages for certain models.\n",
    "\n",
    "### Model Suitability for This Problem\n",
    "\n",
    "- **Neural Network**: Offers flexibility and can capture complex patterns, but may be overkill for this particular dataset. The added complexity comes with longer training times and more hyperparameters to tune.\n",
    "\n",
    "- **Logistic Regression**: Provides excellent performance with much less complexity. It's easier to interpret and faster to train, making it a strong candidate for this problem.\n",
    "\n",
    "- **Decision Tree**: Also performs well and offers interpretability through its decision rules. However, it might be more prone to overfitting on different datasets.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "For the breast cancer classification task, the simpler models (especially Logistic Regression) appear to offer a good balance between performance and complexity. The neural network doesn't provide enough additional benefit to justify its complexity in this case.\n",
    "\n",
    "This highlights an important principle in machine learning: always start with simpler models and only move to more complex ones if there's a clear benefit. The \"right\" model depends not only on performance metrics but also on factors like interpretability, training time, and ease of deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
